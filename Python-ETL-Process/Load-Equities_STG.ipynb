{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b821ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import sqlalchemy as sa\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6115278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "external_folder_path = 'C:/Users/' + username + '/Documents/Projects/Financial_Securities/Custom_Python_Functions/'\n",
    "sys.path.append(external_folder_path)\n",
    "from custom_python_functions import create_connection, clear_table, load_key, decrypt\n",
    "\n",
    "key1 = 'user_key.ky'\n",
    "key_file1 = 'user_key.txt'\n",
    "key2 = 'pass_key.ky'\n",
    "key_file2 = 'pass_key.txt'\n",
    "\n",
    "key1 = load_key(f_path, key1)\n",
    "uid = decrypt(f_path, key_file1, key1)\n",
    "\n",
    "key2 = load_key(f_path, key2)\n",
    "passwd = decrypt(f_path, key_file2, key2)\n",
    "\n",
    "# Setup connection parameters\n",
    "server = 'danvuk.database.windows.net'\n",
    "dbase = 'Financial_Securities'\n",
    "\n",
    "# Create a connection to the database\n",
    "s, e = create_connection(server, dbase, uid, passwd)\n",
    "s1 = s()  # Instantiate a session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0617f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = sa.orm.declarative_base()\n",
    "\n",
    "class Data_STG(Base):\n",
    "    \n",
    "    \"\"\"\n",
    "    SQLAlchemy ORM class representing the 'Data_STG' table in the 'Equities' schema.\n",
    "\n",
    "    Attributes:\n",
    "        __tablename__ (str): The name of the table in the database.\n",
    "        __table_args__ (dict): Additional arguments for the table, including schema name.\n",
    "        Date (Column): The date column, part of the composite primary key.\n",
    "        Description (Column): A description column, part of the composite primary key.\n",
    "        Description2 (Column): An additional description column.\n",
    "        Int_Value1 (Column): An integer column.\n",
    "    \"\"\"\n",
    "    \n",
    "    __tablename__ = 'Data_STG'\n",
    "    __table_args__ = {'schema': 'Equities'}\n",
    "    Date = sa.Column(sa.Date, primary_key=True)\n",
    "    Description = sa.Column(sa.String, primary_key=True)\n",
    "    Description2 = sa.Column(sa.String)\n",
    "    Int_Value1 = sa.Column(sa.Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f71673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the existing data in the Data_STG table\n",
    "clear_table(s1, 'Financial_Securities.Equities.Data_STG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b8eebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database data load is complete\n",
      "All 503 records were loaded into the Data_STG table!\n"
     ]
    }
   ],
   "source": [
    "in_file1 = 'C:/Users/' + username + '/Documents/Projects/Financial_Securities/Data-Source-Files/SP500_GICS_Combined.csv'  # Path to 1st CSV file\n",
    "in_file2 = 'C:/Users/' + username + '/Documents/Projects/Financial_Securities/Data-Source-Files/SP500_Equities_Prices.csv'  # Path to 2nd CSV file\n",
    "\n",
    "curr_date = dt.datetime.now()  # Current date and time\n",
    "\n",
    "# Valisdate if both files exist\n",
    "if (os.path.isfile(in_file1)) and (os.path.isfile(in_file2)):\n",
    "    \n",
    "    # Load the 1st CSV file into 1st DataFrame\n",
    "    df_equities1 = pd.read_csv(in_file1)\n",
    "    \n",
    "    # Load the 2nd CSV file into 2nd DataFrame\n",
    "    df_equities2 = pd.read_csv(in_file2)\n",
    "    \n",
    "    # Drop the last row of comment data coming from Barchart file\n",
    "    df_equities2.drop(df_equities2.tail(1).index, inplace=True)\n",
    "    \n",
    "    # Check if values in df_equities1['Ticker'] exist in df_equities2['Symbol']\n",
    "    matches1 = df_equities1['Ticker'].isin(df_equities2['Symbol'])\n",
    "    all_match1 = matches1.all()\n",
    "    \n",
    "    # Check if values in df_equities2['Symbol'] exist in df_equities1['Ticker']\n",
    "    matches2 = df_equities2['Symbol'].isin(df_equities1['Ticker'])\n",
    "    all_match2 = matches2.all()\n",
    "\n",
    "    # if tickers match in both files, the latest S&P 500 ticker list is valid\n",
    "    if all_match1 and all_match2:\n",
    "                      \n",
    "        # Select relevant columns\n",
    "        df_equities1 = df_equities1[['Ticker', 'Name', 'Sub_Industry_ID']]\n",
    "    \n",
    "        # Iterate through the rows of the DataFrame\n",
    "        for index, row in df_equities1.iterrows():\n",
    "            try:\n",
    "                # Create a new Data_STG instance for each row\n",
    "                q1 = Data_STG(\n",
    "                    Date=curr_date,\n",
    "                    Description=row['Ticker'],\n",
    "                    Description2=row['Name'],\n",
    "                    Int_Value1=row['Sub_Industry_ID']\n",
    "                )\n",
    "                s1.add(q1)  # Add the instance to the session\n",
    "        \n",
    "            # Handle SQLAlchemy errors if they occur during adding the object\n",
    "            except sa.exc.SQLAlchemyError as e:\n",
    "                message = f\"Issue with updating Data_STG database table for Date: {curr_date} and Ticker: {row['Ticker']}. Error: {e}\"\n",
    "                print(message)\n",
    "    \n",
    "        # Commit all changes to the database\n",
    "        s1.commit()\n",
    "    \n",
    "        print(\"Database data load is complete\")\n",
    "    \n",
    "    \n",
    "        # SQL query to count the number of records in the Data_STG table\n",
    "        sql_stat = \"\"\"SELECT COUNT(*) FROM [Financial_Securities].[Equities].[Data_STG]\"\"\"\n",
    "\n",
    "        try: \n",
    "            result = e.execute(sql_stat)  # Execute the count query\n",
    "            cnt_recs = result.scalar()  # Get the count of records\n",
    "    \n",
    "         # Handle SQLAlchemy errors if they occur during query execution\n",
    "        except sa.exc.SQLAlchemyError as e:\n",
    "            # Print the error\n",
    "            print(f\"Issue querying Data_STG database table for count! Error: {e}\")\n",
    "\n",
    "        \n",
    "        # Compare the record counts and print the result    \n",
    "        if cnt_recs < len(df_equities1):\n",
    "            print(f\"Only {cnt_recs} records out of {len(df_equities1)} records were loaded into the Data_STG table!\")\n",
    "        else:\n",
    "            print(f\"All {cnt_recs} records were loaded into the Data_STG table!\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Tickers in the {os.path.basename(in_file1)} file don't match the tickers in the {os.path.basename(in_file1)} file\")\n",
    "\n",
    "else:\n",
    "    print(\"File not found!\")  # Print a message if the file does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851e2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.close()  # Close the session"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ib3.9 Kernel",
   "language": "python",
   "name": "ib3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
